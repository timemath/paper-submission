\documentclass[format=acmsmall, review=false, screen=true]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{upgreek}
\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}


% Metadata Information
\acmJournal{TWEB}
\acmVolume{9}
\acmNumber{4}
\acmArticle{39}
\acmYear{2018}
\acmMonth{3}
\copyrightyear{2018}
%\acmArticleSeq{9}

% Copyright
%\setcopyright{acmcopyright}
\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
%\acmDOI{0000001.0000001}

% Paper history
%\received{February 2007}
%\received[revised]{March 2009}
%\received[accepted]{June 2009}


% Document starts
\begin{document}
% Title portion. Note the short title for running heads
\title[]{DoubleM-KV: A Distributed RDMA-enabled Persistent Memory Key-Value Store with Low Latency and Fast Replication}

\author{Hao Liu}
\orcid{0000-0003-3026-478X}
\affiliation{
	\institution{Tsinghua University}
	\streetaddress{30 Shuangqing Road}
	\city{Haidian District}
	\state{Beijing City}
	\country{China}
}
\email{haoliu@tsinghua.edu.cn}

\author{Youyou Lu}
\affiliation{
	\institution{Tsinghua University}
	\streetaddress{30 Shuangqing Road}
	\city{Haidian District}
	\state{Beijing City}
	\country{China}
}
\email{luyouyou@tsinghua.edu.cn}

\author{Jiwu Shu}
\affiliation{
	\institution{Tsinghua University}
	\streetaddress{30 Shuangqing Road}
	\city{Haidian District}
	\state{Beijing City}
	\country{China}
}
\email{shujw@tsinghua.edu.cn}

\begin{abstract}

	Emerging non-volatile memory(NVM) medium brings revolutionary impact on storage technology landscape. Well-combination of byte-addressability and non-volatility features and comparable performance with DRAM make NVM become a competitive choice for both working memory and persistent storage. RDMA which stands for remote direct memory access is a direct memory access technology from the memory of one computer into that of another without involving either one's operating system. It permits high-throughput, low-latency networking, and has already existed for decades in server clusters and data centers. The promising of NVM makes RDMA technology popular again because the combination of these two technologies offers a clear possibility of constructing a high throughput, low latency and large volume persistent storage platform, such as distributed persistent memory file system and key-value store system. In this paper, we explore the design and implementation of a distributed key-value store system which utilizing both of NVM and RDMA. Our prototype system calls DoubleM-KV, it collects modifications of both data and meta data at the local NVM of the primary server and replicate them to the same positions of backup servers by RDMA writes. Extensive experiment shows that DoubleM-KV achieves significant latency	reduction and fast replication of user data. It stores a 32 bytes key-value pair with a replication degree of 3 in less than 2$\upmu$s and the whole request latency is less than 10$\upmu$s which is only 20\% of that Memcached's request latency under IPoIB protocol.

\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}

\end{CCSXML}
\ccsdesc[500]{Computer systems organization~Storage systems}
\ccsdesc[300]{Computer systems organization~Replication}

%
% End generated code
%

\keywords{Non-Volatile Memory, Key-Value Store, RDMA, Fast Replication}

\maketitle

% The default list of authors is too long for headers.
%\renewcommand{\shortauthors}{G. Zhou et al.}
%\input{samplebody-journals}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

	Fast development of Non-Volatile Memories(NVMs) bring exciting growth point to both of academic research and industrial production in the storage area. The representative NVMs are phase change memory\cite{Wong2010Phase}, STT-RAM\cite{Wang2013Low}, memristor\cite{Zangeneh2014Design} and Intel's 3D XPoint\cite{3dxpoint}. These NVM mediums provide byte-addressability, persistence, high-density and DRAM-like read and write performance. In order to utilizing the unique features of NVM, many recent researches have been proposed from different levels, such as persistent memory file system\cite{dulloor2014system,Zheng2017HMVFS,Volos2013Storage,condit2009better,wu2011scmfs,Ou2016A}, persistent memory key-value store system\cite{203265} and the novel programming models\cite{Hwang2015HEAPO,volos2011mnemosyne,zhang2015mojim} on persistent memory. These researches supply different management methods and various user interfaces for utilizing NVM. Besides the NVM-aware file systems, the NVM-aware NoSQL database systems have also attracting much research attention recently. As a main kind of NoSQL database system, several NVM-based key-value store systems and closely-related data structures\cite{echo,203265,Wu2016NVMcached,Oukid2016FPTree,nv-tree} are proposed for exploring persistent and consistent key-value store service on NVM. These systems mainly focus on the design method on the single-node architecture and solve the problem of persistent and consistent storage of key-value pairs on NVM, but can not well-adopt for the distributed environment applications in modern data centers. At the time, another technology called RDMA brings new opportunity to construct a high-throughput and low-latency distributed key-value store system by combing both NVM and RDMA.
	\par Remote Direct Memory Access(RDMA) is a mature direct memory access technology that enables directly accessing memory on a remote machine through specialized network without involving the remote CPU. RDMA can provide low latency, high bandwidth, low CPU utilization and has been widely adopted in high performance computing environments for decades. Although RDMA is not a novel technology, the recently emerging NVM technology makes it popular again, because the combination of RDMA and NVM will introduce attractive features for fast and low-latency memory storage. These features will supply great benefit for date-intensive applications in the modern data centers. For key-value store system, it offers an special opportunity to construct a distributed, RDMA-enabled, completely in-memory key-value storage system with both data persistence and consistence. State-of-the-art in-memory key-value stores often backup their in-memory data to disk to provide durability. However,the latency and bandwidth gap between disk and DRAM makes it impossible to backup data synchronously. For example, Redis\cite{redis} and RAMCloud\cite{rumble2014log} periodically flush data to disks or SSDs in a user specified time interval, which means the data will be lost if a power failure occurred during this period. The emerging byte-addressable NVM technologies have a comparable read/write latency to DRAM, which makes it an attractive replacement for DRAM and Disk/SSD solution. However, the consistency and fault-tolerance problem for distributed key-value store system still needed to be optimized further. For instance, in a distributed key-value store system, a key-value pair often has several replications, when a server crashed or became inaccessible because of network disconnection, backup servers could still serve requests. PBR with N replications can tolerate N - 1 server failure. Suppose the average crash probability of a server is P(P << 1), then the unavailability of a N replicated storage system equals to PN. In traditional DRAM + Disk/SSD key-value stores with primary backup, the replication procedure is as follows. The primary server first writes to local storage, and then sends request to N - 1 backup servers, it sends response to the client after having received all responses from N - 1 backup servers. By this approach, a request needs to be  executed at	N independent servers, which results in great CPU resource waste and several times of higher latency. When replacing DRAM and Disk/SSD with NVM, the persistency time is	decreased, but the time cost and CPU usage of re-executing the request at backup servers remain if we follow the same replication procedure. In order to reduce the average latency of key-value pair persistent process, we leverage the RDMA technology to realize a distributed low-latency key-value store on NVM named DoubleM-KV. 
	\par In DoubleM-KV, we propose a byte-to-byte replication scheme utilizing one-sided RDMA write of infiniband fabric. For a PUT	request, we first execute the request in primary server, which introduces several data and metadata writes to local NVM. These NVM modifications are then collected and replicated to the same address of backup servers' NVM storage by one-sided RDMA write. In our approach, the re-execution of requests are eliminated, which significantly decreases the replication latency and backup server's CPU usage, because one-sided RDMA write does not invoke the backup servers' CPU. 
		
	\noindent The technical contribution of this paper can be illustrated as follows:

	\begin{itemize}
		\item We design a fast replication mechanism which is optimized for NVM over RDMA fabric.
		\item We implemented a distributed key-value store prototype called DoubleM-KV. We conducted experiments on Mellanox ConnectX-3 NIC to evaluate the performance of our system. Experimental results show that a replication of 32 bytes PUT request to 2 backup servers completes in only around 2$\upmu$s. 
		\item To overcome the limitation of traditional key-value stores, we first explores the design of a distributed low-latency key-value store on non-volatile main memory by leveraging RDMA. 
	\end{itemize}

	The roadmap of this paper is as follows. Section \ref{sec:motivation} presents briefly introduces key-value stores, NVM and RDMA. Section \ref{sec:design} presents our design and describes the replication approach. Section \ref{sec:implementation} shows several important implementation details of DoubleM-KV. In section \ref{sec:evaluation}, we evaluate our work on servers equipped with Mellaonx infiniband. Finally, we conclude our paper in section \ref{sec:conclusion}.
	
\section{Motivation and Background}\label{sec:motivation}
	
	For providing good quality of service in many large-scale web applications, key-value store systems are deployed as an important infrastructure in the data centers. It often adopted as a temporary storage place for high-throughput and low latency data accesses. The data organizing structure and user interfaces of key-value store system are simple and flexible. Distributed key-value store systems offer many advantages over their centralized counterparts. For example, the decentralized structure supports well scalability automatic load balancing and the use of replication in a highly distributed environment can improve reliability and data availability. In our paper, we locate the background of our key-value store system on NVM and RDMA, we motivate our work to solve the problem of fast replication and low-latency access by utilizing NVM and RDMA technologies. Next, we introduce the background of our work respectively.
	 	
\subsection{Non-Volatile Memory}
	
	Next-generation non-volatile memories(NVMs) which is also called Persistent Memory(PM), such as 3D XPoint\cite{3dxpoint}, phase change memory(PCM)\cite{Wong2010Phase}, spin-transfer torque magnetic memory(STT-RAM)\cite{Wang2013Low} and the memristor\cite{Zangeneh2014Design} possess unique features of byte addressability, non-volatility, persistence and comparable read and write latency to that of DRAM. These features make NVM technology holds a great potential to change the landscape of memory and storage industry. If applications want to exploit all the low latency and byte-addressability benefits of PM, they should directly access it via memory load and store instructions without any software overhead. If our system can guarantee the consistency of data which is stored in NVM even after system crash and power failure, the non-volatility of NVM will make it persistent naturally. According to this conclusion, many of the in-memory systems can be reconstructed for NVM, for example, persistent in-memory file system and key-value store system. Unfortunately, most previous durable in-memory systems were designed for the single-node environment. With modern data center applications' computation scale, we have to be able to scale out these single-node PM systems. Under this demand, a distributed system architecture with good scalability and high performance is deserved, and a effective communication network between the single-nodes also affect the whole system performance to a large extent.
	
\subsection{Remote Direct Memory Access}

	Remote Direct Memory Access(RDMA) technology refers to the direct memory access from the memory of one computer into that of another without involving either one's operating system. This method permits high-throughput, low-latency networking, which is especially useful in massively distributed computer clusters and data centers. RDMA supports zero-copy networking by enabling the network adapter to transfer data directly to or from application memory, eliminating the need to copy data between application memory and the data buffers in the operating system. RDMA supports both one-sided and two-sided communication. One-sided RDMA operations directly access memory at a remote node without involving the remote nodeâ€™s CPU. Two-sided RDMA operations inform the remote node of a delivered message. RDMA supports reliable and unreliable connections(RC and UC) and unreliable datagram(UD). The standard interface of native RDMA is a set of operations collectively called	Verbs. Native RDMA allows accesses from both user space	and kernel space using Verbs. 
		
\subsection{Key-Value Store}
	
	Key-value store system is 
	
\section{DoubleM-KV Design}\label{sec:design}

	In this section, we 

\section{Implementation}\label{sec:implementation}
	

\section{Evaluation}\label{sec:evaluation}


\section{Related Work}\label{sec:relatedwork}
	

\section{Conclusion}\label{sec:conclusion}
	
	
	
	
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgement}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography
\bibliographystyle{ACM-Reference-Format}
\bibliography{thesis}


\end{document}
